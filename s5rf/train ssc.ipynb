{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 15:26:30.304368: E external/xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2024-07-03 15:26:30.304694: E external/xla/xla/stream_executor/cuda/cuda_diagnostics.cc:252] kernel version 535.171.4 does not match DSO version 535.183.1 -- cannot find working devices in this configuration\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unable to initialize backend 'cuda': FAILED_PRECONDITION: No visible GPU devices. (you may need to uninstall the failing plugin package, or set JAX_PLATFORMS=cpu to skip this backend.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Development/resonator-hackathon/.venv/lib/python3.9/site-packages/jax/_src/xla_bridge.py:981\u001b[0m, in \u001b[0;36m_init_backend\u001b[0;34m(platform)\u001b[0m\n\u001b[1;32m    980\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing backend \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, platform)\n\u001b[0;32m--> 981\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[43mregistration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;66;03m# TODO(skye): consider raising more descriptive errors directly from backend\u001b[39;00m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# factories instead of returning None.\u001b[39;00m\n",
      "File \u001b[0;32m~/Development/resonator-hackathon/.venv/lib/python3.9/site-packages/jax/_src/xla_bridge.py:679\u001b[0m, in \u001b[0;36mregister_plugin.<locals>.factory\u001b[0;34m()\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m distributed\u001b[38;5;241m.\u001b[39mglobal_state\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 679\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxla_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_c_api_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplugin_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdated_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m distribute_options \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode_id\u001b[39m\u001b[38;5;124m'\u001b[39m: distributed\u001b[38;5;241m.\u001b[39mglobal_state\u001b[38;5;241m.\u001b[39mprocess_id,\n\u001b[1;32m    683\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_nodes\u001b[39m\u001b[38;5;124m'\u001b[39m: distributed\u001b[38;5;241m.\u001b[39mglobal_state\u001b[38;5;241m.\u001b[39mnum_processes,\n\u001b[1;32m    684\u001b[0m }\n",
      "File \u001b[0;32m~/Development/resonator-hackathon/.venv/lib/python3.9/site-packages/jaxlib/xla_client.py:200\u001b[0m, in \u001b[0;36mmake_c_api_client\u001b[0;34m(plugin_name, options, distributed_client)\u001b[0m\n\u001b[1;32m    199\u001b[0m   options \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_xla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_c_api_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplugin_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistributed_client\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: FAILED_PRECONDITION: No visible GPU devices.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     y2 \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mwhere(x \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mgelu(\u001b[38;5;241m-\u001b[39mx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1.1\u001b[39m))\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y1 \u001b[38;5;241m+\u001b[39m y2\n\u001b[0;32m---> 17\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinspace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m ax\u001b[38;5;241m.\u001b[39mplot(x, grad_multi_gaussian(x), label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti gaussian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Development/resonator-hackathon/.venv/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:3503\u001b[0m, in \u001b[0;36mlinspace\u001b[0;34m(start, stop, num, endpoint, retstep, dtype, axis)\u001b[0m\n\u001b[1;32m   3501\u001b[0m num \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mconcrete_or_error(operator\u001b[38;5;241m.\u001b[39mindex, num, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument of jnp.linspace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3502\u001b[0m axis \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mconcrete_or_error(operator\u001b[38;5;241m.\u001b[39mindex, axis, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxis\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument of jnp.linspace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 3503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_linspace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 17 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Development/resonator-hackathon/.venv/lib/python3.9/site-packages/jax/_src/xla_bridge.py:906\u001b[0m, in \u001b[0;36mbackends\u001b[0;34m()\u001b[0m\n\u001b[1;32m    904\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    905\u001b[0m         err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (you may need to uninstall the failing plugin package, or set JAX_PLATFORMS=cpu to skip this backend.)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 906\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(err_msg)\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m _default_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_platforms\u001b[38;5;241m.\u001b[39mvalue:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unable to initialize backend 'cuda': FAILED_PRECONDITION: No visible GPU devices. (you may need to uninstall the failing plugin package, or set JAX_PLATFORMS=cpu to skip this backend.)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")\n",
    "\n",
    "def grad_multi_gaussian(x: jax.Array) -> jax.Array:\n",
    "    h: float=0.15\n",
    "    sigma: float=0.5\n",
    "    s: float=6.\n",
    "    gaussian = lambda x, mu, std: jnp.exp(-0.5*((x-mu)/std)**2) # * 1/((2*jnp.pi)**(0.5) * std)\n",
    "    return (1+h)*gaussian(x, 0, sigma) - h*gaussian(x, sigma, s*sigma) - h*gaussian(x, -sigma, s*sigma)\n",
    "\n",
    "def grad_double_gelu(x: jax.Array) -> jax.Array:\n",
    "    y1 = jnp.where(x < 0, jax.nn.gelu(x+1.1))\n",
    "    y2 = jnp.where(x >= 0, jax.nn.gelu(-x+1.1))\n",
    "    return y1 + y2\n",
    "\n",
    "x = jnp.linspace(-10, 10, 1000)\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(x, grad_multi_gaussian(x), label=\"multi gaussian\")\n",
    "ax.plot(x, grad_double_gelu(x), label=\"double gelu\")\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/thomas/Development/resonator-hackathon/ssm/equinox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/Development/resonator-hackathon/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/thomas/Development/resonator-hackathon/ssm/equinox'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sets the correct path, don't know how to toggle this once it is set\n",
    "%cd ../\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/Development/resonator-hackathon/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import jax \n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "import optax\n",
    "from tqdm import tqdm\n",
    "from typing import Callable\n",
    "import wandb\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from resonator_s5.classifier import Classifier\n",
    "from functools import partial\n",
    "\n",
    "import tonic\n",
    "import tonic.transforms as transforms\n",
    "from tonic import DiskCachedDataset\n",
    "\n",
    "\n",
    "def downsample(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Input: (T, 700)\n",
    "    Output: (T, 140)\n",
    "    \"\"\"\n",
    "    x = x.reshape((-1, 14, 50))\n",
    "    x = x.sum(axis=-1)\n",
    "    return x\n",
    "\n",
    "\n",
    "shd_sensor_size = (700, 1, 1)\n",
    "bins = 250\n",
    "pre_cache_transform = transforms.Compose([\n",
    "    # tonic.transforms.ToFrame(\n",
    "    #     sensor_size=(700, 1, 1), # ssc.sensor_size = (700, 1, 1) \n",
    "    #     time_window=1000,\n",
    "    # ),\n",
    "    # tonic.transforms.CropTime(max=100000),\n",
    "    tonic.transforms.Downsample(sensor_size=shd_sensor_size, target_size=(140, 1)),\n",
    "])\n",
    "post_cache_train_transform = transforms.Compose([\n",
    "    # tonic.transforms.UniformNoise(sensor_size=shd_sensor_size, n=1000),\n",
    "    # tonic.transforms.SpatialJitter(\n",
    "    #         sensor_size=shd_sensor_size, \n",
    "    #         var_x=1, \n",
    "    #         var_y=1, \n",
    "    #         clip_outliers=True\n",
    "    #     ),\n",
    "    tonic.transforms.TimeJitter(std=100, clip_negative=True),\n",
    "    # tonic.transforms.DropEvent(p=0.33),\n",
    "    tonic.transforms.ToFrame(\n",
    "        sensor_size=(140, 1, 1), \n",
    "        n_time_bins=bins,\n",
    "    ),\n",
    "    torchvision.transforms.Lambda(lambda x: x[:, 0, :]),\n",
    "    torchvision.transforms.Lambda(lambda x: (x > 0).astype(np.int32)),\n",
    "])\n",
    "post_cache_val_transform = transforms.Compose([\n",
    "    # tonic.transforms.UniformNoise(sensor_size=shd_sensor_size, n=1000),\n",
    "    # tonic.transforms.SpatialJitter(\n",
    "    #         sensor_size=shd_sensor_size, \n",
    "    #         var_x=1, \n",
    "    #         var_y=1, \n",
    "    #         clip_outliers=True\n",
    "    #     ),\n",
    "    # tonic.transforms.TimeJitter(std=100, clip_negative=True),\n",
    "    # tonic.transforms.DropEvent(p=0.33),\n",
    "    tonic.transforms.ToFrame(\n",
    "        sensor_size=(140, 1, 1), \n",
    "        n_time_bins=bins,\n",
    "    ),\n",
    "    torchvision.transforms.Lambda(lambda x: x[:, 0, :]),\n",
    "    torchvision.transforms.Lambda(lambda x: (x > 0).astype(np.int32)),\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = tonic.datasets.SSC(save_to=\"../../data\", split=\"train\", transform=pre_cache_transform)\n",
    "val_dataset = tonic.datasets.SSC(save_to=\"../../data\", split=\"valid\", transform=pre_cache_transform)\n",
    "test_dataset = tonic.datasets.SSC(save_to=\"../../data\", split=\"test\", transform=pre_cache_transform)\n",
    "\n",
    "train_dataset = DiskCachedDataset(train_dataset, cache_path=\"../../data/tonic/cache/ssc/train\", transform=post_cache_train_transform)\n",
    "val_dataset = DiskCachedDataset(val_dataset, cache_path=\"../../data/tonic/cache/ssc/val\", transform=post_cache_val_transform)\n",
    "test_dataset = DiskCachedDataset(test_dataset, cache_path=\"../../data/tonic/cache/ssc/test\", transform=post_cache_val_transform)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 35\n",
    "EPOCHS = 40\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 250, 140])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(train_dataloader))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 20:40:11.552223: W external/xla/xla/service/gpu/nvptx_compiler.cc:760] The NVIDIA driver's CUDA version is 12.3 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  dense_layers=[\n",
       "    RFDense(\n",
       "      C=f32[128,140,2],\n",
       "      keep_imag=True,\n",
       "      norm=RadialNorm(\n",
       "        norm=LayerNorm(\n",
       "          shape=(128,),\n",
       "          eps=1e-05,\n",
       "          use_weight=True,\n",
       "          use_bias=True,\n",
       "          weight=f32[128],\n",
       "          bias=f32[128]\n",
       "        ),\n",
       "        keep_imag=True\n",
       "      )\n",
       "    ),\n",
       "    RFDense(\n",
       "      C=f32[128,128,2],\n",
       "      keep_imag=True,\n",
       "      norm=RadialNorm(\n",
       "        norm=LayerNorm(\n",
       "          shape=(128,),\n",
       "          eps=1e-05,\n",
       "          use_weight=True,\n",
       "          use_bias=True,\n",
       "          weight=f32[128],\n",
       "          bias=f32[128]\n",
       "        ),\n",
       "        keep_imag=True\n",
       "      )\n",
       "    ),\n",
       "    RFDense(\n",
       "      C=f32[128,128,2],\n",
       "      keep_imag=True,\n",
       "      norm=RadialNorm(\n",
       "        norm=LayerNorm(\n",
       "          shape=(128,),\n",
       "          eps=1e-05,\n",
       "          use_weight=True,\n",
       "          use_bias=True,\n",
       "          weight=f32[128],\n",
       "          bias=f32[128]\n",
       "        ),\n",
       "        keep_imag=True\n",
       "      )\n",
       "    ),\n",
       "    RFDense(\n",
       "      C=f32[128,128,2],\n",
       "      keep_imag=True,\n",
       "      norm=RadialNorm(\n",
       "        norm=LayerNorm(\n",
       "          shape=(128,),\n",
       "          eps=1e-05,\n",
       "          use_weight=True,\n",
       "          use_bias=True,\n",
       "          weight=f32[128],\n",
       "          bias=f32[128]\n",
       "        ),\n",
       "        keep_imag=True\n",
       "      )\n",
       "    ),\n",
       "    RFDense(\n",
       "      C=f32[128,128,2],\n",
       "      keep_imag=True,\n",
       "      norm=RadialNorm(\n",
       "        norm=LayerNorm(\n",
       "          shape=(128,),\n",
       "          eps=1e-05,\n",
       "          use_weight=True,\n",
       "          use_bias=True,\n",
       "          weight=f32[128],\n",
       "          bias=f32[128]\n",
       "        ),\n",
       "        keep_imag=True\n",
       "      )\n",
       "    ),\n",
       "    RFDense(\n",
       "      C=f32[128,128,2],\n",
       "      keep_imag=True,\n",
       "      norm=RadialNorm(\n",
       "        norm=LayerNorm(\n",
       "          shape=(128,),\n",
       "          eps=1e-05,\n",
       "          use_weight=True,\n",
       "          use_bias=True,\n",
       "          weight=f32[128],\n",
       "          bias=f32[128]\n",
       "        ),\n",
       "        keep_imag=True\n",
       "      )\n",
       "    )\n",
       "  ],\n",
       "  neuron_layers=[\n",
       "    RF(\n",
       "      Lambda=f32[128,2],\n",
       "      V=c64[128,128],\n",
       "      log_step=f32[128,1],\n",
       "      keep_imag=True,\n",
       "      discretization='zoh',\n",
       "      activation='cartesian_spike',\n",
       "      bidirectional=False,\n",
       "      step_rescale=1.0\n",
       "    ),\n",
       "    RF(\n",
       "      Lambda=f32[128,2],\n",
       "      V=c64[128,128],\n",
       "      log_step=f32[128,1],\n",
       "      keep_imag=True,\n",
       "      discretization='zoh',\n",
       "      activation='cartesian_spike',\n",
       "      bidirectional=False,\n",
       "      step_rescale=1.0\n",
       "    ),\n",
       "    RF(\n",
       "      Lambda=f32[128,2],\n",
       "      V=c64[128,128],\n",
       "      log_step=f32[128,1],\n",
       "      keep_imag=True,\n",
       "      discretization='zoh',\n",
       "      activation='cartesian_spike',\n",
       "      bidirectional=False,\n",
       "      step_rescale=1.0\n",
       "    ),\n",
       "    RF(\n",
       "      Lambda=f32[128,2],\n",
       "      V=c64[128,128],\n",
       "      log_step=f32[128,1],\n",
       "      keep_imag=True,\n",
       "      discretization='zoh',\n",
       "      activation='cartesian_spike',\n",
       "      bidirectional=False,\n",
       "      step_rescale=1.0\n",
       "    ),\n",
       "    RF(\n",
       "      Lambda=f32[128,2],\n",
       "      V=c64[128,128],\n",
       "      log_step=f32[128,1],\n",
       "      keep_imag=True,\n",
       "      discretization='zoh',\n",
       "      activation='cartesian_spike',\n",
       "      bidirectional=False,\n",
       "      step_rescale=1.0\n",
       "    ),\n",
       "    RF(\n",
       "      Lambda=f32[128,2],\n",
       "      V=c64[128,128],\n",
       "      log_step=f32[128,1],\n",
       "      keep_imag=True,\n",
       "      discretization='zoh',\n",
       "      activation='cartesian_spike',\n",
       "      bidirectional=False,\n",
       "      step_rescale=1.0\n",
       "    )\n",
       "  ],\n",
       "  drop=Dropout(p=0.2, inference=False),\n",
       "  output_dense=RFDense(\n",
       "    C=f32[35,128,2],\n",
       "    keep_imag=False,\n",
       "    norm=RadialNorm(\n",
       "      norm=LayerNorm(\n",
       "        shape=(35,),\n",
       "        eps=1e-05,\n",
       "        use_weight=True,\n",
       "        use_bias=True,\n",
       "        weight=f32[35],\n",
       "        bias=f32[35]\n",
       "      ),\n",
       "      keep_imag=False\n",
       "    )\n",
       "  ),\n",
       "  li=LI(tau=f32[35], dim=35),\n",
       "  apply_skip=True,\n",
       "  dense_dropout=False\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng_key = jax.random.PRNGKey(42)\n",
    "rng_key, model_key = jax.random.split(rng_key, num=2)\n",
    "\n",
    "model = Classifier(\n",
    "    rng_key=model_key,\n",
    "    input_dim=140,\n",
    "    output_dim=NUM_CLASSES,\n",
    "    num_neurons=[128]*6,\n",
    "    # num_neurons=[4],\n",
    "    num_blocks=[16]*6,\n",
    "    # num_blocks=[1],\n",
    "    dt_min=0.001,\n",
    "    dt_max=0.1,\n",
    "    activation=\"cartesian_spike\",\n",
    "    discretization=\"zoh\",\n",
    "    bidirectional=False,\n",
    "    keep_imag=True,\n",
    "    v_pos=\"before_spike\",\n",
    "    apply_skip=True,\n",
    "    dropout=0.2,\n",
    "    dense_dropout = False,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-19.857405  ,  -5.3542137 ,  -1.9577932 ,  -0.427489  ,\n",
       "         0.42748874,   1.9577956 ,   5.354209  ,  19.85741   ,\n",
       "       -19.857405  ,  -5.3542137 ,  -1.9577932 ,  -0.427489  ,\n",
       "         0.42748874,   1.9577956 ,   5.354209  ,  19.85741   ,\n",
       "       -19.857405  ,  -5.3542137 ,  -1.9577932 ,  -0.427489  ,\n",
       "         0.42748874,   1.9577956 ,   5.354209  ,  19.85741   ,\n",
       "       -19.857405  ,  -5.3542137 ,  -1.9577932 ,  -0.427489  ,\n",
       "         0.42748874,   1.9577956 ,   5.354209  ,  19.85741   ,\n",
       "       -19.857405  ,  -5.3542137 ,  -1.9577932 ,  -0.427489  ,\n",
       "         0.42748874,   1.9577956 ,   5.354209  ,  19.85741   ,\n",
       "       -19.857405  ,  -5.3542137 ,  -1.9577932 ,  -0.427489  ,\n",
       "         0.42748874,   1.9577956 ,   5.354209  ,  19.85741   ,\n",
       "       -19.857405  ,  -5.3542137 ,  -1.9577932 ,  -0.427489  ,\n",
       "         0.42748874,   1.9577956 ,   5.354209  ,  19.85741   ,\n",
       "       -19.857405  ,  -5.3542137 ,  -1.9577932 ,  -0.427489  ,\n",
       "         0.42748874,   1.9577956 ,   5.354209  ,  19.85741   ,\n",
       "       -19.857405  ,  -5.3542137 ,  -1.9577932 ,  -0.427489  ,\n",
       "         0.42748874,   1.9577956 ,   5.354209  ,  19.85741   ,\n",
       "       -19.857405  ,  -5.3542137 ,  -1.9577932 ,  -0.427489  ,\n",
       "         0.42748874,   1.9577956 ,   5.354209  ,  19.85741   ,\n",
       "       -19.857405  ,  -5.3542137 ,  -1.9577932 ,  -0.427489  ,\n",
       "         0.42748874,   1.9577956 ,   5.354209  ,  19.85741   ,\n",
       "       -19.857405  ,  -5.3542137 ,  -1.9577932 ,  -0.427489  ,\n",
       "         0.42748874,   1.9577956 ,   5.354209  ,  19.85741   ,\n",
       "       -19.857405  ,  -5.3542137 ,  -1.9577932 ,  -0.427489  ,\n",
       "         0.42748874,   1.9577956 ,   5.354209  ,  19.85741   ,\n",
       "       -19.857405  ,  -5.3542137 ,  -1.9577932 ,  -0.427489  ,\n",
       "         0.42748874,   1.9577956 ,   5.354209  ,  19.85741   ,\n",
       "       -19.857405  ,  -5.3542137 ,  -1.9577932 ,  -0.427489  ,\n",
       "         0.42748874,   1.9577956 ,   5.354209  ,  19.85741   ,\n",
       "       -19.857405  ,  -5.3542137 ,  -1.9577932 ,  -0.427489  ,\n",
       "         0.42748874,   1.9577956 ,   5.354209  ,  19.85741   ],      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.neuron_layers[0].Lambda[...,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.02857143, 0.02857143, 0.02857143, 0.02857143, 0.02857143,\n",
       "       0.02857143, 0.02857143, 0.02857143, 0.02857143, 0.02857143,\n",
       "       0.02857143, 0.02857143, 0.02857143, 0.02857143, 0.02857143,\n",
       "       0.02857143, 0.02857143, 0.02857143, 0.02857143, 0.02857143,\n",
       "       0.02857143, 0.02857143, 0.02857143, 0.02857143, 0.02857143,\n",
       "       0.02857143, 0.02857143, 0.02857143, 0.02857143, 0.02857143,\n",
       "       0.02857143, 0.02857143, 0.02857143, 0.02857143, 0.02857143],      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.exp(model.forward(jnp.ones([4, 140]), rng_key=rng_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resonator_s5.optax_helper import init_optimizer\n",
    "\n",
    "decay_steps = EPOCHS * len(train_dataloader)\n",
    "# if PERMUTE:\n",
    "# standard_lr = 0.004\n",
    "# ssm_lr = 0.001\n",
    "# else:\n",
    "standard_lr = 0.004\n",
    "ssm_lr = 0.004\n",
    "\n",
    "optim, opt_state = init_optimizer(model, standard_lr=standard_lr, ssm_lr=ssm_lr, weight_decay=0.0001, decay_steps=decay_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.004, dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_state.inner_states['standard'].inner_state.hyperparams['learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model: Classifier, train_key, x: jax.Array, y: jax.Array):\n",
    "    call = partial(model.forward, rng_key=train_key)\n",
    "    batched_model = jax.vmap(call, in_axes=(0), out_axes=(0)) # add batch dim to x only\n",
    "    logits = batched_model(x)\n",
    "    loss = optax.softmax_cross_entropy(logits=logits, labels=y)\n",
    "    loss = loss.mean()\n",
    "    return loss, (logits)\n",
    "\n",
    "\n",
    "# x , y = next(iter(test_dataloader))\n",
    "# x = jnp.asarray(x.numpy())\n",
    "# y = jnp.asarray(y.numpy())\n",
    "\n",
    "# value, grads = eqx.filter_value_and_grad(loss_fn, has_aux=True)(model, rng_key, x, y)\n",
    "\n",
    "# lrs = []\n",
    "# for _ in tqdm(range(1080)):\n",
    "#     updates, opt_state = optim.update(grads, opt_state, model)\n",
    "#     lr = opt_state.inner_states['standard'].inner_state.hyperparams['learning_rate']\n",
    "#     lrs.append(lr)\n",
    "\n",
    "# model = eqx.apply_updates(model, updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7a82004e21d0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = jnp.linspace(0, 1080*300)\n",
    "y = 0.008 * (1-1e-6)/2 * (1 + jnp.cos(jnp.pi * x/decay_steps)) + 1e-6\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.004, dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_state.inner_states['standard'].inner_state.hyperparams['learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([2, 1])\n",
    "np.all(x != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jax.jit\n",
    "def cut_mix(x: np.ndarray, y: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Performs cut mix augmentation: https://arxiv.org/pdf/1905.04899 but for a sequence.\n",
    "    Code is deliberately in numpy and not jax.numpy cause it is simpler to work on mutable arrays.\n",
    "    Input:\n",
    "        x: (B, T, C)\n",
    "        y: (B, 1)\n",
    "    Output:\n",
    "        x: (B, T, C)\n",
    "        y: (B, 1)\n",
    "    \"\"\"\n",
    "    B = x.shape[0]\n",
    "    T = x.shape[1]\n",
    "    success = False\n",
    "    while not success:\n",
    "        lmbda = np.random.uniform(low=0, high=1)\n",
    "        rand_index = np.random.permutation(np.arange(B))\n",
    "        \n",
    "        t1 = np.random.randint(low=0, high=T)\n",
    "        t2 = int(T * (1-lmbda))\n",
    "        \n",
    "        t1_cut = np.clip((t1 - t2) // 2, a_min=0, a_max=T)\n",
    "        t2_cut = np.clip((t1 + t2) // 2, a_min=0, a_max=T)\n",
    "\n",
    "        # lmbda = 1 - t2/T\n",
    "        num_spikes2 = x[rand_index, t1_cut:t2_cut, :].sum(axis=(1, 2))\n",
    "        num_spikes1 = x.sum(axis=(1, 2)) - x[:, t1_cut:t2_cut, :].sum(axis=(1, 2))\n",
    "\n",
    "        success = np.all((num_spikes2 + num_spikes1) != 0)\n",
    "\n",
    "    x[:, t1_cut:t2_cut, :] = x[rand_index, t1_cut:t2_cut, :]\n",
    "    \n",
    "    lmbda = num_spikes1 / (num_spikes1 + num_spikes2)\n",
    "    lmbda = lmbda[:, None]\n",
    "    y = lmbda * y + (1-lmbda) * y[rand_index]\n",
    "    return x, y\n",
    "\n",
    "# @jax.jit\n",
    "def one_hot(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Input: (B)\n",
    "    Output: (B)\n",
    "    \"\"\"\n",
    "    # x = x[:, 0]\n",
    "    x = np.eye(NUM_CLASSES)[x]\n",
    "    # x = x[:, None]\n",
    "    return x \n",
    "\n",
    "\n",
    "def prep_data(x: torch.Tensor, y: torch.Tensor, training: bool) -> tuple[jax.Array, jax.Array]:\n",
    "    x = x.numpy()\n",
    "    y = y.numpy()\n",
    "    y = one_hot(y)\n",
    "    if training: \n",
    "        x, y = cut_mix(x, y)\n",
    "    x = jnp.asarray(x)\n",
    "    y = jnp.asarray(y)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(10)\n",
    "np.clip(a=x, a_min=np.ones_like(x), a_max=x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack([np.arange(10), np.ones(10)]).max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "def train_step(model: Classifier, train_key, opt_state, x: jax.Array, y: jax.Array):\n",
    "    (loss_value, (logits)), grads = eqx.filter_value_and_grad(loss_fn, has_aux=True)(model, train_key, x, y)\n",
    "    updates, opt_state = optim.update(grads, opt_state, model)\n",
    "    model = eqx.apply_updates(model, updates)\n",
    "    metrics = {\n",
    "        'loss': loss_value,\n",
    "        'accuracy': jnp.mean(jnp.argmax(logits, axis=-1) == jnp.argmax(y, axis=-1)),\n",
    "    }\n",
    "    return model, opt_state, metrics\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def test_step(model: Classifier, rng_key, x, y):\n",
    "    loss_value, (logits) = loss_fn(model, rng_key, x, y)\n",
    "    metrics = {\n",
    "        'loss': loss_value,\n",
    "        # 'accuracy': jnp.mean(jnp.argmax(logits, -1) == y),\n",
    "        'accuracy': jnp.mean(jnp.argmax(logits, axis=-1) == jnp.argmax(y, axis=-1)),\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def get_average_spikes(model: Classifier, x: jax.Array, layer: int) -> tuple[jax.Array, jax.Array]:\n",
    "    spikes_fn = partial(model.gen_spikes, layer=layer)\n",
    "    spikes = jax.vmap(spikes_fn)(x)\n",
    "    return (jnp.sum(spikes) / BATCH_SIZE).astype(jnp.int32), jnp.mean(spikes)\n",
    "\n",
    "\n",
    "def train_epoch(model: Classifier, rng_key, opt_state, track_layer: int):\n",
    "    train_metrics = {\n",
    "        'loss': [],\n",
    "        'accuracy': [],\n",
    "    }\n",
    "    val_metrics = {\n",
    "        'loss': [],\n",
    "        'accuracy': [],\n",
    "        'num_spikes': [],\n",
    "        'avg_spikes': [],\n",
    "    }\n",
    "    test_metrics = {\n",
    "        'loss': [],\n",
    "        'accuracy': [],\n",
    "        'num_spikes': [],\n",
    "        'avg_spikes': [],\n",
    "    }\n",
    "    print(\"training\")\n",
    "    for x, y in tqdm(train_dataloader):\n",
    "        x, y = prep_data(x, y, training=True)\n",
    "        rng_key, train_key = jax.random.split(rng_key, num=2)\n",
    "        model, opt_state, metric = train_step(model, train_key, opt_state, x, y)\n",
    "        train_metrics['loss'].append(metric['loss'])\n",
    "        train_metrics['accuracy'].append(metric['accuracy'])\n",
    "\n",
    "        # wandb.log({\n",
    "        #      \"loss\": metric[\"loss\"],\n",
    "        #      \"acc\": metric[\"accuracy\"],\n",
    "        # })\n",
    "    \n",
    "    print(\"validating\")\n",
    "    inference_model = eqx.nn.inference_mode(model)\n",
    "    for x, y in tqdm(val_dataloader): \n",
    "        x, y = prep_data(x, y, training=False)\n",
    "        metric = test_step(inference_model, rng_key, x, y)\n",
    "        val_metrics['loss'].append(metric['loss'])\n",
    "        val_metrics['accuracy'].append(metric['accuracy'])\n",
    "\n",
    "    num_spikes, avg_spikes = get_average_spikes(model, x, layer=track_layer)\n",
    "    val_metrics['num_spikes'] = num_spikes\n",
    "    val_metrics['avg_spikes'] = avg_spikes\n",
    "\n",
    "    print(\"testing\")\n",
    "    for x, y in tqdm(test_dataloader): \n",
    "        x, y = prep_data(x, y, training=False)\n",
    "        metric = test_step(inference_model, rng_key, x, y)\n",
    "        test_metrics['loss'].append(metric['loss'])\n",
    "        test_metrics['accuracy'].append(metric['accuracy'])\n",
    "    \n",
    "    num_spikes, avg_spikes = get_average_spikes(model, x, layer=track_layer)\n",
    "    test_metrics['num_spikes'] = num_spikes\n",
    "    test_metrics['avg_spikes'] = avg_spikes\n",
    "\n",
    "    train_metrics['loss'] = jnp.array(train_metrics['loss']).mean()\n",
    "    train_metrics['accuracy'] = jnp.array(train_metrics['accuracy']).mean()\n",
    "    val_metrics['loss'] = jnp.array(val_metrics['loss']).mean()\n",
    "    val_metrics['accuracy'] = jnp.array(val_metrics['accuracy']).mean()\n",
    "    test_metrics['loss'] = jnp.array(test_metrics['loss']).mean()\n",
    "    test_metrics['accuracy'] = jnp.array(test_metrics['accuracy']).mean()\n",
    "\n",
    "    print(f\"Train Loss: {train_metrics['loss']}\")\n",
    "    print(f\"Train Acc: {train_metrics['accuracy']}\")\n",
    "    print(f\"Val Loss: {val_metrics['loss']}\")\n",
    "    print(f\"Val Acc: {val_metrics['accuracy']}\")\n",
    "    print(f\"Test Loss: {test_metrics['loss']}\")\n",
    "    print(f\"Test Acc: {test_metrics['accuracy']}\\n\")\n",
    "\n",
    "    return model, opt_state, train_metrics, val_metrics, test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BestAccTracker:\n",
    "    def __init__(self) -> None:\n",
    "        self.counter = 0\n",
    "        self.best_acc = 0\n",
    "    \n",
    "    def update(self, x: jax.Array | float) -> None:\n",
    "        if x > self.best_acc:\n",
    "            self.best_acc = x\n",
    "            self.reset_counter()\n",
    "        else:\n",
    "            self.counter += 1\n",
    "    \n",
    "    def reset_counter(self) -> None:\n",
    "        self.counter = 0\n",
    "\n",
    "\n",
    "\n",
    "some_nan = lambda x: np.sum(np.isnan(x)) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36/40\n",
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1180/1180 [03:38<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:24<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:50<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8907749652862549\n",
      "Train Acc: 0.5677251219749451\n",
      "Val Loss: 0.9449732899665833\n",
      "Val Acc: 0.7369956374168396\n",
      "Test Loss: 0.9973435401916504\n",
      "Test Acc: 0.7210912704467773\n",
      "\n",
      "Epoch: 37/40\n",
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1180/1180 [03:40<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:24<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:50<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8831005096435547\n",
      "Train Acc: 0.568606972694397\n",
      "Val Loss: 0.9365272521972656\n",
      "Val Acc: 0.739489734172821\n",
      "Test Loss: 0.9889496564865112\n",
      "Test Acc: 0.722315788269043\n",
      "\n",
      "Epoch: 38/40\n",
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1180/1180 [03:42<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:24<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:51<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8890082836151123\n",
      "Train Acc: 0.5696371793746948\n",
      "Val Loss: 0.9351481795310974\n",
      "Val Acc: 0.7401054501533508\n",
      "Test Loss: 0.9884647130966187\n",
      "Test Acc: 0.7217345833778381\n",
      "\n",
      "Epoch: 39/40\n",
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1180/1180 [03:43<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:25<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:51<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8880962133407593\n",
      "Train Acc: 0.5721795558929443\n",
      "Val Loss: 0.9339594841003418\n",
      "Val Acc: 0.7393994331359863\n",
      "Test Loss: 0.987754762172699\n",
      "Test Acc: 0.7223713397979736\n",
      "\n",
      "Epoch: 40/40\n",
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1180/1180 [03:42<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:25<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:51<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8990693092346191\n",
      "Train Acc: 0.5683712363243103\n",
      "Val Loss: 0.9362149238586426\n",
      "Val Acc: 0.7399002313613892\n",
      "Test Loss: 0.9872126579284668\n",
      "Test Acc: 0.7220774292945862\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Counter</td><td>▁▁▁▁▁▁▁▁▂▁▁▂▁▂▁▁▂▄▁▁▁▂▁▁▂▁▂▄▁▂▄▁▂▄▁▂▄▅▇█</td></tr><tr><td>Learning Rate SSM</td><td>██████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Learning Rate Standard</td><td>██████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Max C imag</td><td>▁▂▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇████████████████</td></tr><tr><td>Max C real</td><td>▁▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>Max Delta</td><td>▁▃▆▇▇▇▇▇▇▇▇▇██▇█████████████████████████</td></tr><tr><td>Max Lambda imag</td><td>▁▂▂▄▃▄▃▅▇▆▅▆▆██▇▇▇▇▇▇▇▇███▇▇▇▇▇██▇██████</td></tr><tr><td>Max Lambda real</td><td>▇▁▂▃▅▇█▇█▇▇▇▇██▇▇▇▆▆▆▆▆▄▃▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂</td></tr><tr><td>Max Tau</td><td>▁▃▄▅▄▇▇▇▇▆▇▆▇▇█▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Min C imag</td><td>█▇▆▆▅▅▅▅▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Min C real</td><td>██▇▆▆▆▅▅▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Min Delta</td><td>█▇▆▅▄▄▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>Min Lambda imag</td><td>█▇▅▄▂▂▂▁▂▃▃▃▃▄▃▄▄▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄</td></tr><tr><td>Min Lambda real</td><td>██▇▇▇▆▆▅▄▄▃▃▃▃▃▃▂▂▂▂▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Min Tau</td><td>▂▁▂▄▇▇▇██▇▇▇█▇▇▇▇▇▇█▇█▇▇████████████████</td></tr><tr><td>Test Accuracy</td><td>▁▄▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇██████████████████████</td></tr><tr><td>Test Avg Spikes</td><td>▆▆█▇▅▃▅▄▆▃▂▅▃▁▄▂▄▂▂▂▃▃▄▄▄▄▄▄▅▄▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>Test Loss</td><td>█▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test Num Spikes</td><td>▆▆█▇▅▃▅▄▆▃▂▅▃▁▄▂▄▂▂▂▃▃▄▄▄▄▄▄▅▄▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇████████████████</td></tr><tr><td>Train Loss</td><td>█▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val Accuracy</td><td>▁▄▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇██████████████████████</td></tr><tr><td>Val Avg Spikes</td><td>▄▅█▇▅▂▅▄▆▃▂▄▃▁▄▁▃▂▃▃▃▃▄▄▃▄▄▄▅▄▄▄▄▄▄▅▄▄▄▄</td></tr><tr><td>Val Loss</td><td>█▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val Num Spikes</td><td>▄▅█▇▅▂▅▄▆▃▂▄▃▁▄▁▃▂▃▃▃▃▄▄▃▄▄▄▅▄▄▄▄▄▄▅▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Counter</td><td>5</td></tr><tr><td>Learning Rate SSM</td><td>0.0</td></tr><tr><td>Learning Rate Standard</td><td>0.0</td></tr><tr><td>Max C imag</td><td>3.24594</td></tr><tr><td>Max C real</td><td>2.8136</td></tr><tr><td>Max Delta</td><td>0.42187</td></tr><tr><td>Max Lambda imag</td><td>20.39694</td></tr><tr><td>Max Lambda real</td><td>-0.35942</td></tr><tr><td>Max Tau</td><td>0.8822</td></tr><tr><td>Min C imag</td><td>-2.905</td></tr><tr><td>Min C real</td><td>-3.55613</td></tr><tr><td>Min Delta</td><td>0.00059</td></tr><tr><td>Min Lambda imag</td><td>-20.50189</td></tr><tr><td>Min Lambda real</td><td>-11.67289</td></tr><tr><td>Min Tau</td><td>0.72781</td></tr><tr><td>Test Accuracy</td><td>0.72208</td></tr><tr><td>Test Avg Spikes</td><td>0.08399</td></tr><tr><td>Test Loss</td><td>0.98721</td></tr><tr><td>Test Num Spikes</td><td>1259</td></tr><tr><td>Train Accuracy</td><td>0.56837</td></tr><tr><td>Train Loss</td><td>1.89907</td></tr><tr><td>Val Accuracy</td><td>0.7399</td></tr><tr><td>Val Avg Spikes</td><td>0.08165</td></tr><tr><td>Val Loss</td><td>0.93621</td></tr><tr><td>Val Num Spikes</td><td>2490</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hopeful-wave-19</strong> at: <a href='https://wandb.ai/thomashuber/S5_SSC/runs/akvstwec' target=\"_blank\">https://wandb.ai/thomashuber/S5_SSC/runs/akvstwec</a><br/> View project at: <a href='https://wandb.ai/thomashuber/S5_SSC' target=\"_blank\">https://wandb.ai/thomashuber/S5_SSC</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240618_204020-akvstwec/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "wandb.init(project=\"S5_SSC\")\n",
    "\n",
    "rng_key = jax.random.PRNGKey(42)\n",
    "tracker = BestAccTracker()\n",
    "track_layer = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    if (epoch % 5) == 0: \n",
    "        clear_output(wait=True)\n",
    "    print(f\"Epoch: {epoch+1}/{EPOCHS}\")\n",
    "    model, opt_state, train_metrics, val_metrics, test_metrics = train_epoch(model, rng_key, opt_state, track_layer=track_layer)\n",
    "    tracker.update(val_metrics[\"accuracy\"])\n",
    "\n",
    "    wandb.log({\n",
    "        \"Train Loss\": train_metrics['loss'], \n",
    "        \"Train Accuracy\": train_metrics['accuracy'], \n",
    "        \"Val Loss\": val_metrics['loss'], \n",
    "        \"Val Accuracy\": val_metrics['accuracy'],\n",
    "        \"Test Loss\": test_metrics['loss'], \n",
    "        \"Test Accuracy\": test_metrics['accuracy'],\n",
    "        \"Max Lambda real\": -jnp.exp(model.neuron_layers[track_layer].Lambda[...,0].min()),\n",
    "        \"Min Lambda real\": -jnp.exp(model.neuron_layers[track_layer].Lambda[...,0].max()),\n",
    "        \"Max Lambda imag\": model.neuron_layers[track_layer].Lambda[...,1].max(),\n",
    "        \"Min Lambda imag\": model.neuron_layers[track_layer].Lambda[...,1].min(),\n",
    "        \"Max C real\": model.dense_layers[track_layer].C[...,0].max(),\n",
    "        \"Min C real\": model.dense_layers[track_layer].C[...,0].min(),\n",
    "        \"Max C imag\": model.dense_layers[track_layer].C[...,1].max(),\n",
    "        \"Min C imag\": model.dense_layers[track_layer].C[...,1].min(),\n",
    "        \"Max Delta\": jnp.exp(model.neuron_layers[track_layer].log_step.max()),\n",
    "        \"Min Delta\": jnp.exp(model.neuron_layers[track_layer].log_step.min()),\n",
    "        \"Val Num Spikes\": val_metrics['num_spikes'], \n",
    "        \"Val Avg Spikes\": val_metrics['avg_spikes'],\n",
    "        \"Test Num Spikes\": test_metrics['num_spikes'], \n",
    "        \"Test Avg Spikes\": test_metrics['avg_spikes'],\n",
    "        \"Learning Rate Standard\": opt_state.inner_states['standard'].inner_state.hyperparams['learning_rate'],\n",
    "        \"Learning Rate SSM\": opt_state.inner_states['ssm'].inner_state.hyperparams['learning_rate'],\n",
    "        \"Counter\": tracker.counter,\n",
    "        \"Max Tau\": jnp.exp(model.li.tau.max()),\n",
    "        \"Min Tau\": jnp.exp(model.li.tau.min()),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if tracker.counter >= 20:\n",
    "        lr_standard = opt_state.inner_states['standard'].inner_state.hyperparams['learning_rate']\n",
    "        lr_ssm = opt_state.inner_states['ssm'].inner_state.hyperparams['learning_rate']\n",
    "        lr_standard = max(0.2 * lr_standard, 1e-6) \n",
    "        lr_ssm = max(0.2 * lr_ssm, 1e-6)\n",
    "        opt_state.inner_states['standard'].inner_state.hyperparams['learning_rate'] = lr_standard\n",
    "        opt_state.inner_states['ssm'].inner_state.hyperparams['learning_rate'] = lr_ssm\n",
    "        tracker.reset_counter()\n",
    "\n",
    "    if some_nan(model.neuron_layers[track_layer].Lambda):\n",
    "        print(\"Lambda nan\")\n",
    "        break\n",
    "    if some_nan(model.dense_layers[track_layer].C):\n",
    "        print(\"C nan\")\n",
    "        break\n",
    "    if some_nan(model.neuron_layers[track_layer].log_step):\n",
    "        print(\"Delta nan\")\n",
    "        break\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InjectStatefulHyperparamsState(count=Array(47200, dtype=int32), hyperparams={'b1': Array(0.9, dtype=float32), 'b2': Array(0.999, dtype=float32), 'eps': Array(1.e-08, dtype=float32), 'eps_root': Array(0., dtype=float32), 'learning_rate': Array(4.0000003e-09, dtype=float32), 'weight_decay': Array(1.e-04, dtype=float32)}, hyperparams_states={'learning_rate': WrappedScheduleState(count=Array(47200, dtype=int32))}, inner_state=(ScaleByAdamState(count=Array(47200, dtype=int32), mu=Classifier(\n",
       "  dense_layers=[\n",
       "    RFDense(\n",
       "      C=f32[128,140,2],\n",
       "      keep_imag=None,\n",
       "      norm=RadialNorm(\n",
       "        norm=LayerNorm(\n",
       "          shape=(128,),\n",
       "          eps=1e-05,\n",
       "          use_weight=True,\n",
       "          use_bias=True,\n",
       "          weight=f32[128],\n",
       "          bias=f32[128]\n",
       "        ),\n",
       "        keep_imag=None\n",
       "      )\n",
       "    ),\n",
       "    RFDense(\n",
       "      C=f32[128,128,2],\n",
       "      keep_imag=None,\n",
       "      norm=RadialNorm(\n",
       "        norm=LayerNorm(\n",
       "          shape=(128,),\n",
       "          eps=1e-05,\n",
       "          use_weight=True,\n",
       "          use_bias=True,\n",
       "          weight=f32[128],\n",
       "          bias=f32[128]\n",
       "        ),\n",
       "        keep_imag=None\n",
       "      )\n",
       "    ),\n",
       "    RFDense(\n",
       "      C=f32[128,128,2],\n",
       "      keep_imag=None,\n",
       "      norm=RadialNorm(\n",
       "        norm=LayerNorm(\n",
       "          shape=(128,),\n",
       "          eps=1e-05,\n",
       "          use_weight=True,\n",
       "          use_bias=True,\n",
       "          weight=f32[128],\n",
       "          bias=f32[128]\n",
       "        ),\n",
       "        keep_imag=None\n",
       "      )\n",
       "    ),\n",
       "    RFDense(\n",
       "      C=f32[128,128,2],\n",
       "      keep_imag=None,\n",
       "      norm=RadialNorm(\n",
       "        norm=LayerNorm(\n",
       "          shape=(128,),\n",
       "          eps=1e-05,\n",
       "          use_weight=True,\n",
       "          use_bias=True,\n",
       "          weight=f32[128],\n",
       "          bias=f32[128]\n",
       "        ),\n",
       "        keep_imag=None\n",
       "      )\n",
       "    ),\n",
       "    RFDense(\n",
       "      C=f32[128,128,2],\n",
       "      keep_imag=None,\n",
       "      norm=RadialNorm(\n",
       "        norm=LayerNorm(\n",
       "          shape=(128,),\n",
       "          eps=1e-05,\n",
       "          use_weight=True,\n",
       "          use_bias=True,\n",
       "          weight=f32[128],\n",
       "          bias=f32[128]\n",
       "        ),\n",
       "        keep_imag=None\n",
       "      )\n",
       "    ),\n",
       "    RFDense(\n",
       "      C=f32[128,128,2],\n",
       "      keep_imag=None,\n",
       "      norm=RadialNorm(\n",
       "        norm=LayerNorm(\n",
       "          shape=(128,),\n",
       "          eps=1e-05,\n",
       "          use_weight=True,\n",
       "          use_bias=True,\n",
       "          weight=f32[128],\n",
       "          bias=f32[128]\n",
       "        ),\n",
       "        keep_imag=None\n",
       "      )\n",
       "    )\n",
       "  ],\n",
       "  neuron_layers=[\n",
       "    RF(\n",
       "      Lambda=MaskedNode(),\n",
       "      V=c64[128,128],\n",
       "      log_step=MaskedNode(),\n",
       "      keep_imag=None,\n",
       "      discretization=None,\n",
       "      activation=None,\n",
       "      bidirectional=None,\n",
       "      step_rescale=None\n",
       "    ),\n",
       "    RF(\n",
       "      Lambda=MaskedNode(),\n",
       "      V=c64[128,128],\n",
       "      log_step=MaskedNode(),\n",
       "      keep_imag=None,\n",
       "      discretization=None,\n",
       "      activation=None,\n",
       "      bidirectional=None,\n",
       "      step_rescale=None\n",
       "    ),\n",
       "    RF(\n",
       "      Lambda=MaskedNode(),\n",
       "      V=c64[128,128],\n",
       "      log_step=MaskedNode(),\n",
       "      keep_imag=None,\n",
       "      discretization=None,\n",
       "      activation=None,\n",
       "      bidirectional=None,\n",
       "      step_rescale=None\n",
       "    ),\n",
       "    RF(\n",
       "      Lambda=MaskedNode(),\n",
       "      V=c64[128,128],\n",
       "      log_step=MaskedNode(),\n",
       "      keep_imag=None,\n",
       "      discretization=None,\n",
       "      activation=None,\n",
       "      bidirectional=None,\n",
       "      step_rescale=None\n",
       "    ),\n",
       "    RF(\n",
       "      Lambda=MaskedNode(),\n",
       "      V=c64[128,128],\n",
       "      log_step=MaskedNode(),\n",
       "      keep_imag=None,\n",
       "      discretization=None,\n",
       "      activation=None,\n",
       "      bidirectional=None,\n",
       "      step_rescale=None\n",
       "    ),\n",
       "    RF(\n",
       "      Lambda=MaskedNode(),\n",
       "      V=c64[128,128],\n",
       "      log_step=MaskedNode(),\n",
       "      keep_imag=None,\n",
       "      discretization=None,\n",
       "      activation=None,\n",
       "      bidirectional=None,\n",
       "      step_rescale=None\n",
       "    )\n",
       "  ],\n",
       "  drop=Dropout(p=None, inference=None),\n",
       "  output_dense=RFDense(\n",
       "    C=f32[35,128,2],\n",
       "    keep_imag=None,\n",
       "    norm=RadialNorm(\n",
       "      norm=LayerNorm(\n",
       "        shape=(35,),\n",
       "        eps=1e-05,\n",
       "        use_weight=True,\n",
       "        use_bias=True,\n",
       "        weight=f32[35],\n",
       "        bias=f32[35]\n",
       "      ),\n",
       "      keep_imag=None\n",
       "    )\n",
       "  ),\n",
       "  li=LI(tau=f32[35], dim=None),\n",
       "  apply_skip=None,\n",
       "  dense_dropout=None\n",
       "), nu=Classifier(\n",
       "  dense_layers=[\n",
       "    RFDense(\n",
       "      C=f32[128,140,2],\n",
       "      keep_imag=None,\n",
       "      norm=RadialNorm(\n",
       "        norm=LayerNorm(\n",
       "          shape=(128,),\n",
       "          eps=1e-05,\n",
       "          use_weight=True,\n",
       "          use_bias=True,\n",
       "          weight=f32[128],\n",
       "          bias=f32[128]\n",
       "        ),\n",
       "        keep_imag=None\n",
       "      )\n",
       "    ),\n",
       "    RFDense(\n",
       "      C=f32[128,128,2],\n",
       "      keep_imag=None,\n",
       "      norm=RadialNorm(\n",
       "        norm=LayerNorm(\n",
       "          shape=(128,),\n",
       "          eps=1e-05,\n",
       "          use_weight=True,\n",
       "          use_bias=True,\n",
       "          weight=f32[128],\n",
       "          bias=f32[128]\n",
       "        ),\n",
       "        keep_imag=None\n",
       "      )\n",
       "    ),\n",
       "    RFDense(\n",
       "      C=f32[128,128,2],\n",
       "      keep_imag=None,\n",
       "      norm=RadialNorm(\n",
       "        norm=LayerNorm(\n",
       "          shape=(128,),\n",
       "          eps=1e-05,\n",
       "          use_weight=True,\n",
       "          use_bias=True,\n",
       "          weight=f32[128],\n",
       "          bias=f32[128]\n",
       "        ),\n",
       "        keep_imag=None\n",
       "      )\n",
       "    ),\n",
       "    RFDense(\n",
       "      C=f32[128,128,2],\n",
       "      keep_imag=None,\n",
       "      norm=RadialNorm(\n",
       "        norm=LayerNorm(\n",
       "          shape=(128,),\n",
       "          eps=1e-05,\n",
       "          use_weight=True,\n",
       "          use_bias=True,\n",
       "          weight=f32[128],\n",
       "          bias=f32[128]\n",
       "        ),\n",
       "        keep_imag=None\n",
       "      )\n",
       "    ),\n",
       "    RFDense(\n",
       "      C=f32[128,128,2],\n",
       "      keep_imag=None,\n",
       "      norm=RadialNorm(\n",
       "        norm=LayerNorm(\n",
       "          shape=(128,),\n",
       "          eps=1e-05,\n",
       "          use_weight=True,\n",
       "          use_bias=True,\n",
       "          weight=f32[128],\n",
       "          bias=f32[128]\n",
       "        ),\n",
       "        keep_imag=None\n",
       "      )\n",
       "    ),\n",
       "    RFDense(\n",
       "      C=f32[128,128,2],\n",
       "      keep_imag=None,\n",
       "      norm=RadialNorm(\n",
       "        norm=LayerNorm(\n",
       "          shape=(128,),\n",
       "          eps=1e-05,\n",
       "          use_weight=True,\n",
       "          use_bias=True,\n",
       "          weight=f32[128],\n",
       "          bias=f32[128]\n",
       "        ),\n",
       "        keep_imag=None\n",
       "      )\n",
       "    )\n",
       "  ],\n",
       "  neuron_layers=[\n",
       "    RF(\n",
       "      Lambda=MaskedNode(),\n",
       "      V=c64[128,128],\n",
       "      log_step=MaskedNode(),\n",
       "      keep_imag=None,\n",
       "      discretization=None,\n",
       "      activation=None,\n",
       "      bidirectional=None,\n",
       "      step_rescale=None\n",
       "    ),\n",
       "    RF(\n",
       "      Lambda=MaskedNode(),\n",
       "      V=c64[128,128],\n",
       "      log_step=MaskedNode(),\n",
       "      keep_imag=None,\n",
       "      discretization=None,\n",
       "      activation=None,\n",
       "      bidirectional=None,\n",
       "      step_rescale=None\n",
       "    ),\n",
       "    RF(\n",
       "      Lambda=MaskedNode(),\n",
       "      V=c64[128,128],\n",
       "      log_step=MaskedNode(),\n",
       "      keep_imag=None,\n",
       "      discretization=None,\n",
       "      activation=None,\n",
       "      bidirectional=None,\n",
       "      step_rescale=None\n",
       "    ),\n",
       "    RF(\n",
       "      Lambda=MaskedNode(),\n",
       "      V=c64[128,128],\n",
       "      log_step=MaskedNode(),\n",
       "      keep_imag=None,\n",
       "      discretization=None,\n",
       "      activation=None,\n",
       "      bidirectional=None,\n",
       "      step_rescale=None\n",
       "    ),\n",
       "    RF(\n",
       "      Lambda=MaskedNode(),\n",
       "      V=c64[128,128],\n",
       "      log_step=MaskedNode(),\n",
       "      keep_imag=None,\n",
       "      discretization=None,\n",
       "      activation=None,\n",
       "      bidirectional=None,\n",
       "      step_rescale=None\n",
       "    ),\n",
       "    RF(\n",
       "      Lambda=MaskedNode(),\n",
       "      V=c64[128,128],\n",
       "      log_step=MaskedNode(),\n",
       "      keep_imag=None,\n",
       "      discretization=None,\n",
       "      activation=None,\n",
       "      bidirectional=None,\n",
       "      step_rescale=None\n",
       "    )\n",
       "  ],\n",
       "  drop=Dropout(p=None, inference=None),\n",
       "  output_dense=RFDense(\n",
       "    C=f32[35,128,2],\n",
       "    keep_imag=None,\n",
       "    norm=RadialNorm(\n",
       "      norm=LayerNorm(\n",
       "        shape=(35,),\n",
       "        eps=1e-05,\n",
       "        use_weight=True,\n",
       "        use_bias=True,\n",
       "        weight=f32[35],\n",
       "        bias=f32[35]\n",
       "      ),\n",
       "      keep_imag=None\n",
       "    )\n",
       "  ),\n",
       "  li=LI(tau=f32[35], dim=None),\n",
       "  apply_skip=None,\n",
       "  dense_dropout=None\n",
       ")), EmptyState(), EmptyState()))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_state.inner_states['standard'].inner_state#.hyperparams['learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[ 0.5612016 ,  0.24061255],\n",
       "        [ 0.09483978,  0.18571655],\n",
       "        [-0.14064732,  1.1366497 ],\n",
       "        ...,\n",
       "        [-0.12996866, -0.49846843],\n",
       "        [ 0.5404331 , -0.8442935 ],\n",
       "        [-0.07383841, -1.1170496 ]],\n",
       "\n",
       "       [[-0.8365227 , -0.57221526],\n",
       "        [-0.22534093,  0.858842  ],\n",
       "        [ 1.7784208 , -0.7163357 ],\n",
       "        ...,\n",
       "        [-0.00929436,  0.32410818],\n",
       "        [ 0.30637085,  0.35014072],\n",
       "        [-0.21457562,  0.70076746]],\n",
       "\n",
       "       [[ 0.0574888 , -0.8637586 ],\n",
       "        [-0.64097637, -1.2214905 ],\n",
       "        [ 1.0241233 , -0.99533176],\n",
       "        ...,\n",
       "        [ 0.4151726 ,  0.37747246],\n",
       "        [-0.07557665,  0.8084335 ],\n",
       "        [ 0.08066111,  0.6787049 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.02335975, -0.01589949],\n",
       "        [ 1.0454738 ,  0.15441346],\n",
       "        [ 0.6679944 ,  0.12644981],\n",
       "        ...,\n",
       "        [ 0.890263  , -0.18520698],\n",
       "        [ 1.2244103 , -0.5750573 ],\n",
       "        [ 0.90659887, -0.8349935 ]],\n",
       "\n",
       "       [[-0.12791693, -0.9422269 ],\n",
       "        [ 0.13146015,  0.21181895],\n",
       "        [-0.75444496, -0.6741837 ],\n",
       "        ...,\n",
       "        [ 0.39684898, -0.43957326],\n",
       "        [ 0.31970918, -0.02437881],\n",
       "        [ 0.6781248 , -0.9292114 ]],\n",
       "\n",
       "       [[ 2.0025277 , -1.0452111 ],\n",
       "        [ 1.1385145 , -2.692539  ],\n",
       "        [ 0.8111474 , -0.7746177 ],\n",
       "        ...,\n",
       "        [-0.18134487,  0.29233983],\n",
       "        [-0.4284134 ,  0.67920154],\n",
       "        [-0.70767653,  0.71370226]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dense_layers[0].C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-3.446196 ],\n",
       "       [-4.0523095],\n",
       "       [-7.414656 ],\n",
       "       [-5.1316743],\n",
       "       [-1.3078438],\n",
       "       [-2.9639528],\n",
       "       [-4.534997 ],\n",
       "       [-4.8199096],\n",
       "       [-3.684426 ],\n",
       "       [-2.5869176],\n",
       "       [-2.8252864],\n",
       "       [-7.1607327],\n",
       "       [-6.4738727],\n",
       "       [-1.9090204],\n",
       "       [-5.038769 ],\n",
       "       [-5.634285 ],\n",
       "       [-4.373396 ],\n",
       "       [-3.2266722],\n",
       "       [-3.5400832],\n",
       "       [-6.808921 ],\n",
       "       [-5.312518 ],\n",
       "       [-2.4331856],\n",
       "       [-5.678553 ],\n",
       "       [-6.637503 ],\n",
       "       [-3.8560238],\n",
       "       [-3.8020449],\n",
       "       [-5.8722577],\n",
       "       [-5.9108486],\n",
       "       [-5.7063017],\n",
       "       [-2.7967448],\n",
       "       [-4.461726 ],\n",
       "       [-5.138158 ],\n",
       "       [-3.979386 ],\n",
       "       [-6.501038 ],\n",
       "       [-2.7595172],\n",
       "       [-2.5429664],\n",
       "       [-6.3601737],\n",
       "       [-2.4241514],\n",
       "       [-3.5795934],\n",
       "       [-3.5895524],\n",
       "       [-5.7809215],\n",
       "       [-2.6502302],\n",
       "       [-3.5499427],\n",
       "       [-6.4383698],\n",
       "       [-1.4990965],\n",
       "       [-2.0045643],\n",
       "       [-5.1629157],\n",
       "       [-4.1397977],\n",
       "       [-2.1568875],\n",
       "       [-2.456764 ],\n",
       "       [-3.8187678],\n",
       "       [-3.8870225],\n",
       "       [-1.0826956],\n",
       "       [-3.3857217],\n",
       "       [-6.231103 ],\n",
       "       [-5.263215 ],\n",
       "       [-4.3421097],\n",
       "       [-2.909832 ],\n",
       "       [-5.3679504],\n",
       "       [-3.0119793],\n",
       "       [-5.416758 ],\n",
       "       [-2.6866624],\n",
       "       [-5.365711 ],\n",
       "       [-3.9169164],\n",
       "       [-3.5328777],\n",
       "       [-1.7460529],\n",
       "       [-5.2148657],\n",
       "       [-7.25576  ],\n",
       "       [-1.9497968],\n",
       "       [-1.450781 ],\n",
       "       [-6.200205 ],\n",
       "       [-3.1439044],\n",
       "       [-5.152275 ],\n",
       "       [-2.9368362],\n",
       "       [-4.742053 ],\n",
       "       [-6.709483 ],\n",
       "       [-5.8666573],\n",
       "       [-2.4826856],\n",
       "       [-4.286703 ],\n",
       "       [-6.3056855],\n",
       "       [-4.6606064],\n",
       "       [-2.2559798],\n",
       "       [-4.9623795],\n",
       "       [-3.3670387],\n",
       "       [-6.9894276],\n",
       "       [-6.539547 ],\n",
       "       [-0.8630674],\n",
       "       [-5.325162 ],\n",
       "       [-2.9287803],\n",
       "       [-2.9646115],\n",
       "       [-7.4364357],\n",
       "       [-1.3762461],\n",
       "       [-2.9976091],\n",
       "       [-6.748829 ],\n",
       "       [-6.900238 ],\n",
       "       [-3.3286514],\n",
       "       [-6.3206697],\n",
       "       [-2.7188532],\n",
       "       [-7.011791 ],\n",
       "       [-4.4440837],\n",
       "       [-1.4495032],\n",
       "       [-2.5004606],\n",
       "       [-3.4198048],\n",
       "       [-4.4010386],\n",
       "       [-1.7277274],\n",
       "       [-5.850881 ],\n",
       "       [-4.5101066],\n",
       "       [-4.4356017],\n",
       "       [-4.69667  ],\n",
       "       [-3.3827698],\n",
       "       [-3.0798192],\n",
       "       [-3.5689774],\n",
       "       [-2.5074887],\n",
       "       [-4.3805113],\n",
       "       [-4.1695333],\n",
       "       [-4.88177  ],\n",
       "       [-6.1208224],\n",
       "       [-6.902354 ],\n",
       "       [-2.6727626],\n",
       "       [-6.825372 ],\n",
       "       [-3.4847748],\n",
       "       [-1.4060559],\n",
       "       [-6.767178 ],\n",
       "       [-6.2364106],\n",
       "       [-1.7433457],\n",
       "       [-7.0679054],\n",
       "       [-4.2370763],\n",
       "       [-6.2019534]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.neuron_layers[0].log_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[  1.9329531 , -19.100328  ],\n",
       "       [  1.2198097 ,  -5.619456  ],\n",
       "       [  1.0152681 ,  -2.4111097 ],\n",
       "       [  2.0834892 ,  -1.036959  ],\n",
       "       [  0.3605228 ,   0.7464873 ],\n",
       "       [  0.8492885 ,   2.7275515 ],\n",
       "       [  1.1237726 ,   5.6097946 ],\n",
       "       [  1.7914962 ,  19.989573  ],\n",
       "       [  1.0130281 , -19.755547  ],\n",
       "       [  1.0444394 ,  -5.11604   ],\n",
       "       [  0.5557074 ,  -2.3900132 ],\n",
       "       [  0.555835  ,   1.0623438 ],\n",
       "       [  1.9873435 ,   1.8435651 ],\n",
       "       [  0.15442324,   2.1219215 ],\n",
       "       [  1.7716149 ,   5.1477413 ],\n",
       "       [  1.8913652 ,  19.421059  ],\n",
       "       [  1.2105979 , -19.425982  ],\n",
       "       [  0.49248794,  -5.362897  ],\n",
       "       [  0.1957226 ,  -3.0087101 ],\n",
       "       [  1.585769  ,  -1.1395358 ],\n",
       "       [  2.035081  ,   1.4296837 ],\n",
       "       [  0.17942618,   3.2882044 ],\n",
       "       [  1.8872374 ,   5.8967533 ],\n",
       "       [  1.1169449 ,  20.311756  ],\n",
       "       [  1.4086263 , -19.145153  ],\n",
       "       [  0.79197246,  -5.917852  ],\n",
       "       [  1.6169649 ,  -2.0988743 ],\n",
       "       [  2.0355442 ,  -0.50854653],\n",
       "       [  1.7617282 ,  -0.15220705],\n",
       "       [  0.10922875,   1.917179  ],\n",
       "       [  1.1717383 ,   6.1897516 ],\n",
       "       [  1.3591725 ,  19.023022  ],\n",
       "       [  1.5007317 , -19.599852  ],\n",
       "       [  1.9116244 ,  -5.9643273 ],\n",
       "       [  0.44497767,  -2.721107  ],\n",
       "       [  0.17746098,  -1.4863666 ],\n",
       "       [  2.2676136 ,   0.07181723],\n",
       "       [  0.27943867,   2.3169346 ],\n",
       "       [  0.8868589 ,   5.5643373 ],\n",
       "       [  1.4043914 ,  19.390743  ],\n",
       "       [  1.5946991 , -20.501888  ],\n",
       "       [  0.75547636,  -5.5135007 ],\n",
       "       [  0.71609294,  -2.230663  ],\n",
       "       [  2.3737872 ,  -0.52925974],\n",
       "       [  0.26667973,   0.40492463],\n",
       "       [  0.4082377 ,   2.310452  ],\n",
       "       [  1.9089012 ,   6.517174  ],\n",
       "       [  1.6787014 ,  17.929523  ],\n",
       "       [  1.4075568 , -19.095217  ],\n",
       "       [  0.614486  ,  -5.7997575 ],\n",
       "       [  0.5981122 ,  -1.2607856 ],\n",
       "       [  0.4610147 ,  -0.22097756],\n",
       "       [ -1.0232528 ,   1.2078699 ],\n",
       "       [  0.47066662,   1.8008562 ],\n",
       "       [ -0.12577613,   4.9268346 ],\n",
       "       [  1.6664966 ,  19.747381  ],\n",
       "       [  1.540592  , -19.780901  ],\n",
       "       [  0.5103677 ,  -5.058013  ],\n",
       "       [  1.4227506 ,  -1.8367244 ],\n",
       "       [  0.453534  ,  -0.50562745],\n",
       "       [  1.779627  ,   0.7730864 ],\n",
       "       [  0.5526502 ,   2.946642  ],\n",
       "       [  2.050717  ,   5.4468093 ],\n",
       "       [  1.5378174 ,  19.258604  ],\n",
       "       [  1.2114083 , -20.170238  ],\n",
       "       [  0.04382592,  -5.938714  ],\n",
       "       [  1.3069849 ,  -2.8826451 ],\n",
       "       [  0.23479374,  -1.3347002 ],\n",
       "       [  0.7805391 ,   0.49161136],\n",
       "       [ -0.11869725,   2.9579017 ],\n",
       "       [  2.389039  ,   4.5606112 ],\n",
       "       [  1.3858451 ,  18.627186  ],\n",
       "       [  1.474768  , -19.829374  ],\n",
       "       [  0.46965772,  -5.1793184 ],\n",
       "       [  1.5183402 ,  -1.8080266 ],\n",
       "       [  1.2772936 ,  -0.15859215],\n",
       "       [  1.1657535 ,   1.8683352 ],\n",
       "       [ -0.22336096,   2.308087  ],\n",
       "       [  1.0432674 ,   6.0827456 ],\n",
       "       [  1.24315   ,  20.396942  ],\n",
       "       [  1.8635768 , -20.450447  ],\n",
       "       [  1.6841979 ,  -5.306631  ],\n",
       "       [  2.3435457 ,  -2.5762527 ],\n",
       "       [  0.76235205,  -1.3002512 ],\n",
       "       [  2.457269  ,   0.865073  ],\n",
       "       [  1.8980671 ,   1.6960287 ],\n",
       "       [  0.5504856 ,   6.6237655 ],\n",
       "       [  1.5228401 ,  19.652458  ],\n",
       "       [  0.54525584, -20.192087  ],\n",
       "       [  0.548178  ,  -5.2127843 ],\n",
       "       [  1.0294312 ,  -1.9711609 ],\n",
       "       [ -0.48303026,  -1.683086  ],\n",
       "       [  0.6546365 ,   1.4537209 ],\n",
       "       [  0.51150644,   1.8333786 ],\n",
       "       [  0.58141834,   4.4468517 ],\n",
       "       [  0.9742065 ,  18.385614  ],\n",
       "       [  1.8590583 , -20.16513   ],\n",
       "       [  0.9153244 ,  -4.789202  ],\n",
       "       [  1.5790452 ,  -2.9250197 ],\n",
       "       [  1.7986275 ,  -0.5266483 ],\n",
       "       [  0.10544622,   0.5563562 ],\n",
       "       [  0.74702144,   2.0717084 ],\n",
       "       [  1.4706146 ,   5.2832985 ],\n",
       "       [  1.7841014 ,  17.986753  ],\n",
       "       [  0.23053326, -20.450743  ],\n",
       "       [  1.5721653 ,  -6.7500043 ],\n",
       "       [  1.3383791 ,  -2.3032877 ],\n",
       "       [  1.2143307 ,  -0.7959598 ],\n",
       "       [  1.5901017 ,   0.7897735 ],\n",
       "       [  0.8217643 ,   2.309143  ],\n",
       "       [  0.64678186,   5.881071  ],\n",
       "       [  1.2405498 ,  19.352041  ],\n",
       "       [  0.6725683 , -20.03439   ],\n",
       "       [  1.1014193 ,  -4.1611557 ],\n",
       "       [  1.5398372 ,  -2.2784934 ],\n",
       "       [  1.5160155 ,  -0.685556  ],\n",
       "       [  1.6028366 ,   0.17207207],\n",
       "       [  1.8732132 ,   1.7986444 ],\n",
       "       [  0.61396766,   5.5324516 ],\n",
       "       [  1.5444032 ,  19.721975  ],\n",
       "       [  1.1631736 , -18.986197  ],\n",
       "       [  1.37172   ,  -5.9898624 ],\n",
       "       [  0.64598215,  -1.3238325 ],\n",
       "       [  0.4315823 ,  -0.45253095],\n",
       "       [  0.05312835,   0.5563393 ],\n",
       "       [ -0.5255378 ,   2.2169523 ],\n",
       "       [  1.079976  ,   5.310477  ],\n",
       "       [  1.620634  ,  19.216005  ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.neuron_layers[0].Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m()\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise Exception()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots for Surrogat Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = jnp.linspace(-3, 3, 100)\n",
    "h = 0.15\n",
    "s = 6\n",
    "sigma = 0.5\n",
    "theta = 0\n",
    "gaussian1 = lambda x, mu, std: jnp.exp(-0.5*((x-mu)/std)**2)\n",
    "\n",
    "df1 = (1+h)*gaussian1(x, theta, sigma) - 2*h*gaussian1(x, theta, s*sigma)\n",
    "\n",
    "plt.plot(x, df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = jnp.linspace(-3, 3, 100)\n",
    "h = 0.15\n",
    "s = 6\n",
    "sigma = 0.5\n",
    "theta = 0\n",
    "gaussian2 = lambda x, mu, std: 1/((2*jnp.pi)**(0.5) * std) * jnp.exp(-0.5*((x-mu)/std)**2)\n",
    "\n",
    "df2 = (1+h)*gaussian2(x, theta, sigma) - h*gaussian2(x, sigma, s*sigma) - h*gaussian2(x, -sigma, s*sigma)\n",
    "\n",
    "plt.plot(x, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = jnp.linspace(-3, 3, 100)\n",
    "h = 0.15\n",
    "s = 6\n",
    "sigma = 0.5\n",
    "theta = 0\n",
    "gaussian2 = lambda x, mu, std: 1/((2*jnp.pi)**(0.5) * std) * jnp.exp(-0.5*((x-mu)/std)**2)\n",
    "\n",
    "df3 = (4 / (jnp.exp(-x) + jnp.exp(x))**2).astype(jnp.float32)\n",
    "\n",
    "plt.plot(x, df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "P0 = lambda x: np.ones_like(x)\n",
    "P1 = lambda x: x\n",
    "P2 = lambda x: (1/2) * (3 * x**2 - 1)\n",
    "P3 = lambda x: (1/2) * (5 * x**3 - 3*x)\n",
    "P4 = lambda x: (1/8) * (35 * x**4 - 30*x**2 + 3)\n",
    "P5 = lambda x: (1/8) * (63 * x**5 - 70*x**3 + 15*x)\n",
    "P6 = lambda x: (1/16) * (231 * x**6 - 315*x**4 + 105*x**2-5)\n",
    "\n",
    "factor = lambda n: (2*n+1) / 2\n",
    "\n",
    "x = np.linspace(-6, 6, 100)\n",
    "x0 = 0.5\n",
    "y = factor(0)*P0(x0)*P0(x) * factor(1)*P1(x0)*P1(x) * factor(2)*P2(x0)*P2(x) * factor(3)*P3(x0)*P3(x) * factor(4)*P4(x0)*P4(x) * factor(5)*P5(x0)*P5(x) * factor(6)*P6(x0)*P6(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, P6(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin(m, x):\n",
    "    # return 2**(0.5) * np.sin(2*np.pi * m * x)\n",
    "    return np.sin(2*np.pi * m * x)\n",
    "\n",
    "def cos(m, x):\n",
    "    # return 2**(0.5) * np.cos(2*np.pi * m * x)\n",
    "    return np.cos(2*np.pi * m * x)\n",
    "\n",
    "def basis(n, x):\n",
    "    if np.abs(n) % 2 == 0:\n",
    "        return sin(n/2, x)\n",
    "    else:\n",
    "        return cos(int(n/2), x)\n",
    "\n",
    "\n",
    "x = np.linspace(-5, 5, 100)\n",
    "x0 = 2.1\n",
    "y = np.sum(np.array([basis(n, x0) * basis(n, x) for n in range(-64, 64, 1)]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0, 0, 1, 0, 0]\n",
    "np.fft.fft(y*2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
